{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12739635,"sourceType":"datasetVersion","datasetId":8052882},{"sourceId":12746638,"sourceType":"datasetVersion","datasetId":8057830}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-13T03:47:43.734866Z","iopub.execute_input":"2025-08-13T03:47:43.735100Z","iopub.status.idle":"2025-08-13T03:47:44.016406Z","shell.execute_reply.started":"2025-08-13T03:47:43.735083Z","shell.execute_reply":"2025-08-13T03:47:44.015816Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/english-ai-dataset-small/EN_AI_Dec_small.csv\n/kaggle/input/bangla-ai-dataset/BD_AI_Dec.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## Dataset Importing","metadata":{}},{"cell_type":"code","source":"bn_df = pd.read_csv('/kaggle/input/bangla-ai-dataset/BD_AI_Dec.csv')\nprint(bn_df['label'].value_counts())\nbn_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T03:47:44.017552Z","iopub.execute_input":"2025-08-13T03:47:44.017896Z","iopub.status.idle":"2025-08-13T03:47:44.092434Z","shell.execute_reply.started":"2025-08-13T03:47:44.017879Z","shell.execute_reply":"2025-08-13T03:47:44.091864Z"}},"outputs":[{"name":"stdout","text":"label\n1    978\n0    768\nName: count, dtype: int64\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                                                text  label\n0  \"সাহিত্যিক অবদানের জন্য তিনি পাকিস্তান সরকারের...      0\n1  শিকারি পাখি হলো এমন পাখি, যারা ছোট প্রাণী শিকা...      0\n2  এ্যানথ্রাক্স সংক্রমণ পশুসম্পদের উপর বিরূপ প্রভ...      0\n3  ইলিশ নদী ও সমুদ্রের মিলনস্থলে বেশি পাওয়া যায়...      0\n4  তাদের বিবাহ উৎসব ঐতিহ্যগতভাবে হয়। বাবা-মা বিয...      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>\"সাহিত্যিক অবদানের জন্য তিনি পাকিস্তান সরকারের...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>শিকারি পাখি হলো এমন পাখি, যারা ছোট প্রাণী শিকা...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>এ্যানথ্রাক্স সংক্রমণ পশুসম্পদের উপর বিরূপ প্রভ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ইলিশ নদী ও সমুদ্রের মিলনস্থলে বেশি পাওয়া যায়...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>তাদের বিবাহ উৎসব ঐতিহ্যগতভাবে হয়। বাবা-মা বিয...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"en_df = pd.read_csv('/kaggle/input/english-ai-dataset-small/EN_AI_Dec_small.csv')\nprint(en_df['label'].value_counts())\nen_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T03:47:44.093043Z","iopub.execute_input":"2025-08-13T03:47:44.093218Z","iopub.status.idle":"2025-08-13T03:47:44.423509Z","shell.execute_reply.started":"2025-08-13T03:47:44.093203Z","shell.execute_reply":"2025-08-13T03:47:44.422728Z"}},"outputs":[{"name":"stdout","text":"label\n0    2500\n1    2500\nName: count, dtype: int64\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   label                                               text\n0      0  From Trailville\\n\\nUpper Des Plaines River Can...\n1      0  Coca-Cola Company’s Performance Measurement Es...\n2      0  I can't stop it, you won't like it, you should...\n3      0  American Sniper, the Clint Eastwood movie abou...\n4      0  eating them.'' His jaw was clenched so tight t...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>From Trailville\\n\\nUpper Des Plaines River Can...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>Coca-Cola Company’s Performance Measurement Es...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>I can't stop it, you won't like it, you should...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>American Sniper, the Clint Eastwood movie abou...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>eating them.'' His jaw was clenched so tight t...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"en_df = en_df.sample(frac=1, random_state=42).reset_index(drop=True)\nen_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T03:47:44.425005Z","iopub.execute_input":"2025-08-13T03:47:44.425215Z","iopub.status.idle":"2025-08-13T03:47:44.449874Z","shell.execute_reply.started":"2025-08-13T03:47:44.425198Z","shell.execute_reply":"2025-08-13T03:47:44.449295Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   label                                               text\n0      0  ine glasses. He ’ s clearly counting on rule n...\n1      1  New at SubtleTV! Close\\n\\nVideo: Video: Misfit...\n2      1  \\nSome great books to read are To Kill a Mocki...\n3      0  Reflection on Neo-Confucian Discourse Essay\\n\\...\n4      0  How Are Notions of Masculinity Represented in ...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>ine glasses. He ’ s clearly counting on rule n...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>New at SubtleTV! Close\\n\\nVideo: Video: Misfit...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>\\nSome great books to read are To Kill a Mocki...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>Reflection on Neo-Confucian Discourse Essay\\n\\...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>How Are Notions of Masculinity Represented in ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"bangla_df = bn_df\nenglish_df = en_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T03:47:44.450424Z","iopub.execute_input":"2025-08-13T03:47:44.450597Z","iopub.status.idle":"2025-08-13T03:47:44.454205Z","shell.execute_reply.started":"2025-08-13T03:47:44.450576Z","shell.execute_reply":"2025-08-13T03:47:44.453511Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"bangla_df['language'] = 'bn'  # Bangla\nenglish_df['language'] = 'en'  # English","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T03:47:44.454901Z","iopub.execute_input":"2025-08-13T03:47:44.455202Z","iopub.status.idle":"2025-08-13T03:47:44.472123Z","shell.execute_reply.started":"2025-08-13T03:47:44.455182Z","shell.execute_reply":"2025-08-13T03:47:44.471432Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"combined_df = pd.concat([bangla_df, english_df], ignore_index=True)\nprint(f\"Combined dataset shape: {combined_df.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T03:47:44.472814Z","iopub.execute_input":"2025-08-13T03:47:44.473057Z","iopub.status.idle":"2025-08-13T03:47:44.493025Z","shell.execute_reply.started":"2025-08-13T03:47:44.473039Z","shell.execute_reply":"2025-08-13T03:47:44.492199Z"}},"outputs":[{"name":"stdout","text":"Combined dataset shape: (6746, 3)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"combined_df = combined_df.sample(frac=1, random_state=42).reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T03:47:44.493852Z","iopub.execute_input":"2025-08-13T03:47:44.494122Z","iopub.status.idle":"2025-08-13T03:47:44.513013Z","shell.execute_reply.started":"2025-08-13T03:47:44.494097Z","shell.execute_reply":"2025-08-13T03:47:44.512492Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"## Import Packages","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import (\n    AutoTokenizer, \n    AutoModelForSequenceClassification,\n    TrainingArguments, \n    Trainer,\n    EarlyStoppingCallback\n)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T03:47:44.513581Z","iopub.execute_input":"2025-08-13T03:47:44.513824Z","iopub.status.idle":"2025-08-13T03:48:26.534279Z","shell.execute_reply.started":"2025-08-13T03:47:44.513797Z","shell.execute_reply":"2025-08-13T03:48:26.533502Z"}},"outputs":[{"name":"stderr","text":"2025-08-13 03:48:07.013849: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1755056887.400020      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1755056887.512009      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"class MultilingualTextDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_length=512):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n    \n    def __len__(self):\n        return len(self.texts)\n    \n    def __getitem__(self, idx):\n        text = str(self.texts[idx])\n        label = self.labels[idx]\n        \n        # Tokenize text\n        encoding = self.tokenizer(\n            text,\n            truncation=True,\n            padding='max_length',\n            max_length=self.max_length,\n            return_tensors='pt'\n        )\n        \n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'labels': torch.tensor(label, dtype=torch.long)\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T03:48:26.536614Z","iopub.execute_input":"2025-08-13T03:48:26.537633Z","iopub.status.idle":"2025-08-13T03:48:26.542918Z","shell.execute_reply.started":"2025-08-13T03:48:26.537614Z","shell.execute_reply":"2025-08-13T03:48:26.542117Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"class MultilingualAIDetector(nn.Module):\n    def __init__(self, model_name='csebuetnlp/banglabert', num_labels=2, dropout_rate=0.1):\n        super().__init__()\n        self.model = AutoModelForSequenceClassification.from_pretrained(\n            model_name,\n            num_labels=num_labels,\n            output_attentions=False,\n            output_hidden_states=False\n        )\n        \n        # Add additional dropout for better generalization\n        self.dropout = nn.Dropout(dropout_rate)\n        \n    def forward(self, input_ids, attention_mask, labels=None):\n        outputs = self.model(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            labels=labels\n        )\n        return outputs\n\n# Initialize model and tokenizer\nMODEL_NAME = 'xlm-roberta-base'  # Best for multilingual tasks\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\nmodel = MultilingualAIDetector(MODEL_NAME)\n\nprint(f\"Model loaded: {MODEL_NAME}\")\nprint(f\"Vocabulary size: {tokenizer.vocab_size}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T03:48:26.543945Z","iopub.execute_input":"2025-08-13T03:48:26.544289Z","iopub.status.idle":"2025-08-13T03:48:35.133942Z","shell.execute_reply.started":"2025-08-13T03:48:26.544265Z","shell.execute_reply":"2025-08-13T03:48:35.133309Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f733acf40a046388316f9d25023175f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d89088a86c0411f82c4948da123c216"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"854275bf4bf64740b68ef84b9eacb36b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40a80bb7b45c4db69808e2279de59cf7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10cb6524b7744e9ebb65d29df79d7910"}},"metadata":{}},{"name":"stderr","text":"Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Model loaded: xlm-roberta-base\nVocabulary size: 250002\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Prepare the data\ntexts = combined_df['text'].tolist()\nlabels = combined_df['label'].tolist()\nlanguages = combined_df['language'].tolist()\n\n# Stratified split to maintain language and label balance\ntrain_texts, temp_texts, train_labels, temp_labels = train_test_split(\n    texts, labels, \n    test_size=0.3, \n    random_state=42, \n    stratify=labels\n)\n\nval_texts, test_texts, val_labels, test_labels = train_test_split(\n    temp_texts, temp_labels,\n    test_size=0.5,\n    random_state=42,\n    stratify=temp_labels\n)\n\nprint(f\"Training samples: {len(train_texts)}\")\nprint(f\"Validation samples: {len(val_texts)}\")\nprint(f\"Test samples: {len(test_texts)}\")\n\n# Create datasets\ntrain_dataset = MultilingualTextDataset(train_texts, train_labels, tokenizer)\nval_dataset = MultilingualTextDataset(val_texts, val_labels, tokenizer)\ntest_dataset = MultilingualTextDataset(test_texts, test_labels, tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T03:48:35.134584Z","iopub.execute_input":"2025-08-13T03:48:35.134774Z","iopub.status.idle":"2025-08-13T03:48:35.152934Z","shell.execute_reply.started":"2025-08-13T03:48:35.134759Z","shell.execute_reply":"2025-08-13T03:48:35.152240Z"}},"outputs":[{"name":"stdout","text":"Training samples: 4722\nValidation samples: 1012\nTest samples: 1012\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    \"\"\"Compute accuracy, precision, recall, and F1-score\"\"\"\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    \n    precision, recall, f1, _ = precision_recall_fscore_support(\n        labels, predictions, average='weighted'\n    )\n    accuracy = accuracy_score(labels, predictions)\n    \n    return {\n        'accuracy': accuracy,\n        'f1': f1,\n        'precision': precision,\n        'recall': recall\n    }\n\n\ntraining_args = TrainingArguments(\n    output_dir='./AITD_Exp_2',\n    num_train_epochs=5,  \n    per_device_train_batch_size=8, \n    per_device_eval_batch_size=16,\n    warmup_steps=200,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    logging_steps=100,\n    eval_strategy='epoch',\n    # eval_steps=200,\n    save_strategy='epoch',\n    # save_steps=400,\n    load_best_model_at_end=True,\n    metric_for_best_model='f1',\n    greater_is_better=True,\n    report_to='none',  \n    save_total_limit=2,\n    learning_rate=2e-5,\n    gradient_accumulation_steps=2,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T03:48:35.153809Z","iopub.execute_input":"2025-08-13T03:48:35.154092Z","iopub.status.idle":"2025-08-13T03:48:35.220426Z","shell.execute_reply.started":"2025-08-13T03:48:35.154068Z","shell.execute_reply":"2025-08-13T03:48:35.219640Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Initialize trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    compute_metrics=compute_metrics,\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n)\n\n# Train the model\nprint(\"Starting training...\")\ntrainer.train()\n\n# Save the best model\ntrainer.save_model('./best_multilingual_ai_detector')\ntokenizer.save_pretrained('./best_multilingual_ai_detector')\n\nprint(\"Training completed and model saved!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T03:48:35.221265Z","iopub.execute_input":"2025-08-13T03:48:35.221540Z","iopub.status.idle":"2025-08-13T04:17:28.070637Z","shell.execute_reply.started":"2025-08-13T03:48:35.221519Z","shell.execute_reply":"2025-08-13T04:17:28.069737Z"}},"outputs":[{"name":"stdout","text":"Starting training...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='740' max='740' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [740/740 28:44, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.634900</td>\n      <td>0.568834</td>\n      <td>0.715415</td>\n      <td>0.687374</td>\n      <td>0.814412</td>\n      <td>0.715415</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.442100</td>\n      <td>0.514124</td>\n      <td>0.794466</td>\n      <td>0.784638</td>\n      <td>0.847580</td>\n      <td>0.794466</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.308900</td>\n      <td>0.442149</td>\n      <td>0.803360</td>\n      <td>0.794410</td>\n      <td>0.854995</td>\n      <td>0.803360</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.269600</td>\n      <td>0.407074</td>\n      <td>0.838933</td>\n      <td>0.836628</td>\n      <td>0.853292</td>\n      <td>0.838933</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.203200</td>\n      <td>0.472234</td>\n      <td>0.838933</td>\n      <td>0.834981</td>\n      <td>0.866484</td>\n      <td>0.838933</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Training completed and model saved!\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T04:17:28.071759Z","iopub.execute_input":"2025-08-13T04:17:28.072306Z","iopub.status.idle":"2025-08-13T04:17:28.082884Z","shell.execute_reply.started":"2025-08-13T04:17:28.072273Z","shell.execute_reply":"2025-08-13T04:17:28.082091Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"MultilingualAIDetector(\n  (model): XLMRobertaForSequenceClassification(\n    (roberta): XLMRobertaModel(\n      (embeddings): XLMRobertaEmbeddings(\n        (word_embeddings): Embedding(250002, 768, padding_idx=1)\n        (position_embeddings): Embedding(514, 768, padding_idx=1)\n        (token_type_embeddings): Embedding(1, 768)\n        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (encoder): XLMRobertaEncoder(\n        (layer): ModuleList(\n          (0-11): 12 x XLMRobertaLayer(\n            (attention): XLMRobertaAttention(\n              (self): XLMRobertaSdpaSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): XLMRobertaSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): XLMRobertaIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): XLMRobertaOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n        )\n      )\n    )\n    (classifier): XLMRobertaClassificationHead(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n      (out_proj): Linear(in_features=768, out_features=2, bias=True)\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n)"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"# Evaluate on test set\ntest_results = trainer.evaluate(test_dataset)\nprint(\"Test Results:\")\nfor key, value in test_results.items():\n    print(f\"{key}: {value:.4f}\")\n\ndef evaluate_by_language(texts, labels, languages, model, tokenizer):\n    \"\"\"Evaluate model performance by language\"\"\"\n    \n    # Get the device the model is on\n    device = next(model.parameters()).device\n    \n    # Create test dataset\n    test_dataset = MultilingualTextDataset(texts, labels, tokenizer)\n    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n    \n    model.eval()\n    all_predictions = []\n    all_labels = []\n    \n    with torch.no_grad():\n        for batch in test_loader:\n            # Move batch tensors to the same device as the model\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels_batch = batch['labels'].to(device)\n            \n            outputs = model(\n                input_ids=input_ids,\n                attention_mask=attention_mask\n            )\n            predictions = torch.argmax(outputs.logits, dim=1)\n            \n            # Move back to CPU for numpy operations\n            all_predictions.extend(predictions.cpu().numpy())\n            all_labels.extend(labels_batch.cpu().numpy())\n    \n    # Rest of your function remains the same...\n    all_predictions = np.array(all_predictions)\n    all_labels = np.array(all_labels)\n    languages = np.array(languages)\n    \n    # Evaluate by language\n    for lang in ['bn', 'en']:\n        lang_mask = languages == lang\n        if np.sum(lang_mask) > 0:\n            lang_preds = all_predictions[lang_mask]\n            lang_labels = all_labels[lang_mask]\n            \n            accuracy = accuracy_score(lang_labels, lang_preds)\n            precision, recall, f1, _ = precision_recall_fscore_support(\n                lang_labels, lang_preds, average='weighted'\n            )\n            \n            lang_name = 'Bangla' if lang == 'bn' else 'English'\n            print(f\"\\n{lang_name} Performance:\")\n            print(f\"Accuracy: {accuracy:.4f}\")\n            print(f\"Precision: {precision:.4f}\")\n            print(f\"Recall: {recall:.4f}\")\n            print(f\"F1-Score: {f1:.4f}\")\n\n\n# Get language info for test set (you'll need to track this)\ntest_languages = []\nfor text in test_texts:\n    # Simple heuristic: if contains Bangla characters, mark as 'bn'\n    if any('\\u0980' <= char <= '\\u09FF' for char in text):\n        test_languages.append('bn')\n    else:\n        test_languages.append('en')\n\n# Evaluate by language\nevaluate_by_language(test_texts, test_labels, test_languages, model, tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T04:17:28.083788Z","iopub.execute_input":"2025-08-13T04:17:28.084100Z","iopub.status.idle":"2025-08-13T04:18:24.172370Z","shell.execute_reply.started":"2025-08-13T04:17:28.084075Z","shell.execute_reply":"2025-08-13T04:18:24.171753Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [32/32 00:19]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Test Results:\neval_loss: 0.3898\neval_accuracy: 0.8350\neval_f1: 0.8322\neval_precision: 0.8523\neval_recall: 0.8350\neval_runtime: 20.5249\neval_samples_per_second: 49.3060\neval_steps_per_second: 1.5590\nepoch: 5.0000\n\nBangla Performance:\nAccuracy: 0.5874\nPrecision: 0.6008\nRecall: 0.5874\nF1-Score: 0.5577\n\nEnglish Performance:\nAccuracy: 0.9246\nPrecision: 0.9329\nRecall: 0.9246\nF1-Score: 0.9241\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"def predict_text(text, model, tokenizer, device=None):\n    \"\"\"Predict if text is AI-generated or human-written\"\"\"\n    \n    # Auto-detect device if not provided\n    if device is None:\n        device = next(model.parameters()).device\n    \n    model.eval()\n    \n    # Tokenize input and move to correct device\n    inputs = tokenizer(\n        text,\n        truncation=True,\n        padding='max_length',\n        max_length=512,\n        return_tensors='pt'\n    )\n    \n    # Move all input tensors to the same device as model\n    inputs = {key: value.to(device) for key, value in inputs.items()}\n    \n    with torch.no_grad():\n        outputs = model(**inputs)\n        probabilities = torch.softmax(outputs.logits, dim=1)\n        prediction = torch.argmax(outputs.logits, dim=1)\n    \n    confidence = probabilities[0][prediction].item()\n    pred_label = prediction.item()\n    \n    result = {\n        'prediction': 'AI-generated' if pred_label == 1 else 'Human-written',\n        'confidence': confidence,\n        'probabilities': {\n            'human': probabilities[0][0].item(),\n            'ai': probabilities[0][1].item()\n        }\n    }\n    \n    return result\n\n# Example usage\nsample_bangla = \"আর্টিফিশিয়াল ইন্টেলিজেন্স আমাদের জীবনে নতুন সম্ভাবনার দ্বার উন্মোচন করেছে।\"\nsample_english = \"Artificial intelligence has revolutionized the way we interact with technology.\"\n\nprint(\"Bangla text prediction:\")\nresult_bn = predict_text(sample_bangla, model, tokenizer)\nprint(f\"Prediction: {result_bn['prediction']}\")\nprint(f\"Confidence: {result_bn['confidence']:.4f}\")\n\nprint(\"\\nEnglish text prediction:\")\nresult_en = predict_text(sample_english, model, tokenizer)\nprint(f\"Prediction: {result_en['prediction']}\")\nprint(f\"Confidence: {result_en['confidence']:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T04:18:24.173133Z","iopub.execute_input":"2025-08-13T04:18:24.173344Z","iopub.status.idle":"2025-08-13T04:18:24.315527Z","shell.execute_reply.started":"2025-08-13T04:18:24.173327Z","shell.execute_reply":"2025-08-13T04:18:24.314579Z"}},"outputs":[{"name":"stdout","text":"Bangla text prediction:\nPrediction: AI-generated\nConfidence: 0.6950\n\nEnglish text prediction:\nPrediction: AI-generated\nConfidence: 0.9969\n","output_type":"stream"}],"execution_count":17}]}